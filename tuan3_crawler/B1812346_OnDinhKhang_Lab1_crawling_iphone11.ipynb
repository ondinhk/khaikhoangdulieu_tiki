{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B1812346_OnDinhKhang_Lab1_crawling_iphone11.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0HX9nyIJ5nVP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HX9nyIJ5nVP"
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LdzrO5hk7t7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa8d58e-151b-4369-9b91-9b45d3368fc6"
      },
      "source": [
        "!pip install html5lib\n",
        "!pip install lxml\n",
        "\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib) (0.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |████████████████████████████████| 958 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-21.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.8 wsproto-1.0.0\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [872 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.0 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,823 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,516 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,463 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [738 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,241 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [771 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,954 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 14.7 MB in 5s (3,120 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 95.3 MB of archives.\n",
            "After this operation, 327 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 97.0.4692.71-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 97.0.4692.71-0ubuntu0.18.04.1 [84.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 97.0.4692.71-0ubuntu0.18.04.1 [4,370 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 97.0.4692.71-0ubuntu0.18.04.1 [5,055 kB]\n",
            "Fetched 95.3 MB in 6s (15.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_97.0.4692.71-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckY1qfrW5rCm"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7sjbAo0urLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b999759-0199-41e0-d096-0d04ad08ec51"
      },
      "source": [
        "import sys\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "import bs4\n",
        "import requests as rq\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qsQSzz-5swP"
      },
      "source": [
        "# setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgksxOZr50Qw"
      },
      "source": [
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTp2BhXdJBI"
      },
      "source": [
        "SESSION = requests.Session()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function"
      ],
      "metadata": {
        "id": "jhghDRsYB7uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HEADERS = {\n",
        "    'user-agent': (\n",
        "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36')\n",
        "}\n",
        "# set url export file\n",
        "url_export = '/content/drive/My Drive/review_tgdd.json'\n",
        "# Export file review_tgdd.json\n",
        "def exportFile():\n",
        "    with open(url_export, 'w') as file:\n",
        "        json.dump(ARRAY, file, ensure_ascii=False)\n",
        "    print('number of comment')\n",
        "    print(len(ARRAY))\n",
        "\n",
        "def count_page():\n",
        "    # Connect\n",
        "    BASE_URL = 'https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=1'\n",
        "    response = rq.get(BASE_URL, headers=HEADERS)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    # get navbar page\n",
        "    div_navbar = soup.find('div', {'class': 'pagcomment'})\n",
        "    # get value link a\n",
        "    numPage = div_navbar.find_all('a')\n",
        "    max_page = 0\n",
        "    # get maximum number of pages\n",
        "    for a in numPage:\n",
        "        # try to convert string to int\n",
        "        try:\n",
        "            num = int(a.text)\n",
        "        except:\n",
        "            # continue if not convert (exam: >>, ...)\n",
        "            continue\n",
        "        max_page = max(max_page, num)\n",
        "    return max_page\n",
        "\n",
        "\n",
        "# Crawl with page number\n",
        "def crawl(page):\n",
        "    # Get response\n",
        "    URL = 'https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p='\n",
        "    # Cralw page ?=page\n",
        "    BASE_URL = URL + str(page)\n",
        "    print(BASE_URL)\n",
        "    response = rq.get(BASE_URL, headers=HEADERS)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    # find div containing comment\n",
        "    Comment = soup.find('div', {'class': 'comment--all'})\n",
        "    # get all comment -> list item comment\n",
        "    allComment = Comment.find_all('div', {'class': 'comment__item'})\n",
        "    # get comment item\n",
        "    for item in allComment:\n",
        "        # get username\n",
        "        itemName = item.find('p', class_='txtname').get_text()\n",
        "        itemComment = item.find('p', class_='cmt-txt').get_text()\n",
        "        # count class icon-star == rate star\n",
        "        starsTag = item.find_all('i', {'class': 'icon-star'})\n",
        "        rateStar = len(starsTag)\n",
        "        if starsTag is None:\n",
        "            rateStar = 2\n",
        "        # add object to temp\n",
        "        temp = {'username': itemName, 'comment': itemComment, 'rate': rateStar}\n",
        "        # add temp to ARRAY\n",
        "        ARRAY.append(temp)\n"
      ],
      "metadata": {
        "id": "L1ytwWpECBkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "_QAdbE7rDGxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Temp arr\n",
        "ARRAY = []\n",
        "numberOfComment = 0\n",
        "# Get max numpage\n",
        "max_page = count_page()\n",
        "# Crawl all page\n",
        "for i in range(max_page):\n",
        "    crawl(i + 1)\n",
        "# Export file json\n",
        "exportFile()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX2D1ckgDKJ4",
        "outputId": "3b7ef2d6-92f0-41b8-fe8f-0c0867cdf2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=1\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=2\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=3\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=4\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=5\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=6\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=7\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=8\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=9\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=10\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=11\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=12\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=13\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=14\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=15\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=16\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=17\n",
            "https://www.thegioididong.com/dtdd/iphone-11/danh-gia?p=18\n",
            "number of comment\n",
            "1179\n"
          ]
        }
      ]
    }
  ]
}